{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLPOr-8b1WvD"
   },
   "source": [
    "<a href=\"https://www.inove.com.ar\"><img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/PA%20Banner.png\" width=\"1000\" align=\"center\"></a>\n",
    "\n",
    "\n",
    "# Regresión\n",
    "\n",
    "Programa creado para mostrar ejemplos prácticos de los visto durante la clase<br>\n",
    "v1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsIb5f1lnP_U"
   },
   "source": [
    "### Objetivos: \n",
    "*   Introducción a regresiones.\n",
    "*   Conocer como funciona la regresión lineal.\n",
    "*   Evaluar el resultado de una regresión lineal.\n",
    "*   Comprender como funciona la regresión polinomial.\n",
    "*   Evaluar el resultado de una regresión polinomial considerando el grado y el error mínimo.\n",
    "*   Conocer como funciona la regresión con gradiente descendente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBftKJxBVQ-9"
   },
   "source": [
    "# Machine Learning supervisado - Regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkFATpYfVUzT"
   },
   "source": [
    "## 1 - Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yzvdYxQKO5uL"
   },
   "outputs": [],
   "source": [
    "#Librerias a implementar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZxHiXADRMv9b"
   },
   "outputs": [],
   "source": [
    "# df DataFrame creado a partir de pd.DataFrame, cuyas columnas son; x, y\n",
    "df = pd.DataFrame({\n",
    "      \"x\": [1, 5, 10, 15, 20, 25, 30],\n",
    "      \"y\": [5, 12, 11, 23, 19, 28, 36]}\n",
    "      )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tEPJcWe1sqEO"
   },
   "outputs": [],
   "source": [
    "# Separar los datos \"X\" e y\n",
    "# Se utiliza .values para acceder solo a los valores de las columnas.\n",
    "X = df['x'].values\n",
    "y = df['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2L8b3X559_1d"
   },
   "outputs": [],
   "source": [
    "# Se graficar los valores de X e y en un scatterplot (Gráfico de dispersión)\n",
    "# Se crea el espacio para dibujar con fig = plt.figure()\n",
    "# Se crea el espacio para el gráfico ax = fig.add_subplot()\n",
    "# sns, alias Seaborn\n",
    "# Método que representa el gráfico de dispersión\n",
    "# Necesita los valores de X, y \n",
    "# label es la etiqueta que representa el significado de la línea del gráfico.\n",
    "# ax=ax, es el eje base preexistentes para la representación gráfica horizontal.\n",
    "# ax.legend(), para ver la leyenda\n",
    "# ax.grid('dashed'), para ver la grilla indicando el tipo.\n",
    "# Muestra la figura\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "sns.scatterplot(x=X, y=y, label='datos', ax=ax, color='blue')\n",
    "ax.legend()\n",
    "ax.grid('dashed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvgvzvw7_GMs"
   },
   "source": [
    "## 2 - Modelo Base (promediador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4JrLO7WaiVU"
   },
   "outputs": [],
   "source": [
    "# Creamos una función base promediador\n",
    "# Recibe todos los valores de X\n",
    "# Divide y con cada X y de los resultados calcula el promedio en W\n",
    "# La función retorna el resultado de multiplicar cada valor de X por el promedio\n",
    "# y la variable W que a su vez representa la pendiente.\n",
    "\n",
    "def predecir(X):\n",
    "   W = np.mean(y / X)\n",
    "   return (X * W), W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26IvtRzEauQU"
   },
   "outputs": [],
   "source": [
    "# Se invoca a la función y pasandole los valore de X\n",
    "# creando las dos variables que van a capturar los valores de y_hat_base y la pendiente\n",
    "y_hat_base, pendiente = predecir(X)\n",
    "print(y_hat_base)\n",
    "print(f'Pendiente: {pendiente:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cEXYPvCK_fiN"
   },
   "outputs": [],
   "source": [
    "# Graficar los datos y la recta del promediador\n",
    "# variable \"pendiente\" almacena el valor de la pendiente obtenido de la función\n",
    "# Variable X con los valores de X\n",
    "# Punto de donde parte la recta desde el eje y\n",
    "# recta_promediador calcula todos los puntos de la recta promediador\n",
    "# a través de la ecuación de la recta=m.x+b\n",
    "recta_promediador =  pendiente * X + 0\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "# Código para el gráfico de dispersión\n",
    "sns.scatterplot(x=X, y=y, label='datos', ax=ax, color='blue')\n",
    "\n",
    "# Código para el gráfico de la recta del promediador\n",
    "sns.lineplot(x=X, y=recta_promediador, label='promediador', color='darkviolet', ax=ax)\n",
    "ax.legend()\n",
    "ax.grid('dashed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-GGzEPSAq0X"
   },
   "source": [
    "## 3 - Algoritmo de Regresión lineal (y = m*x + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ojm24yvGAm-V"
   },
   "outputs": [],
   "source": [
    "# Se importa la herramienta de sklearn.linear_model como LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Se crea el objeto lr a partir que significa Regresión lineal a partir de la clase LinearRegression()\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Del objeto lr se puede acceder al método fit con la notación del punto\n",
    "# Necesita los valores de X haciendole un ajuste con reshape para que haga el entrenamiento junto a los \n",
    "# valores de y\n",
    "lr.fit(X.reshape(-1, 1), y)\n",
    "\n",
    "# Luego del objeto lr se puede acceder al método predict() que se encarga de hacer las precciones para cada\n",
    "# valor de X\n",
    "y_hat= lr.predict(X.reshape(-1, 1))\n",
    "\n",
    "# Del objeto lr se puede acceder a los métodos coef_[0] (pendiente) y intercept(corte en el eje y) \n",
    "print(f\"Pendiente (W1): {lr.coef_[0]:.2f}\")\n",
    "print(f\"Ordenada al origen (W0): {lr.intercept_:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y71oXpX2Bbf8"
   },
   "outputs": [],
   "source": [
    "# Graficar la recta de la regresión lineal y el promediador\n",
    "# Variable \"pendiente\" almacena  el valor de la pendiente obtenido de la función\n",
    "# Variable X con los valores de X\n",
    "# Punto de donde parte la recta desde el eje y\n",
    "# recta_promediador calcula todos los puntos de la recta promediador\n",
    "# a través de la ecuación de la recta=m.x+b\n",
    "recta_promediador =  pendiente * X + 0\n",
    "\n",
    "ly2 = X * lr.coef_ + lr.intercept_\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "# Código para el gráfico de dispersión\n",
    "sns.scatterplot(x=X, y=y, label='datos', ax=ax, color='blue')\n",
    "\n",
    "# Código para los gráficos de línea (uno para promediador, el otro para regresión)\n",
    "sns.lineplot(x=X, y=recta_promediador, label='promediador', ax=ax, color='darkviolet')\n",
    "sns.lineplot(x=X, y=ly2, label='regresion', color='y', ax=ax)\n",
    "ax.legend()\n",
    "ax.grid('dashed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrT85LqaKj3c"
   },
   "source": [
    "## 4 - Métricas para la regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JXUOSnbVKo2_"
   },
   "outputs": [],
   "source": [
    "# Es un coeficiente de determinación, determina la capacidad de un modelo para predecir futuros resultados. \n",
    "# El mejor resultado posible es 1.0\n",
    "# Fuente: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html\n",
    "# Se importa la herramienta de sklearn.metrics como r2_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# r2_score necesita los valore a comparar los reales por un lado y los de la predicción por otro \n",
    "# Se comparan ambos resultados\n",
    "lr_r2 = r2_score(y, y_hat)\n",
    "base_r2 = r2_score(y, y_hat_base)\n",
    "\n",
    "print(f\"Promediador: coeficiente de determinación: {base_r2:.2f}\")\n",
    "print(f\"Regresión: coeficiente de deterinación: {lr_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_e0LUY2fYcTf"
   },
   "source": [
    "## 5 - Regresión polinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FIDcW5Z1bb-I"
   },
   "outputs": [],
   "source": [
    "def coseno(X):\n",
    "    return np.cos(1.5 * np.pi * X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6nWNp4AbXiS"
   },
   "outputs": [],
   "source": [
    "# Los valores X_train, y_train, X_test e y_test estarán contenidos por valores artificiales\n",
    "\n",
    "# Número de valores que tendrá X_train e y_train \n",
    "n_samples = 30\n",
    "\n",
    "# Se arma una matriz ordenada con números aleatorios hasta el 30\n",
    "X_train = np.sort(np.random.rand(n_samples))\n",
    "\n",
    "# Los valores de y_train se obtendrán a través de la función coseno más el resultado de \n",
    "# multiplicar X_train * 0.1\n",
    "y_train = coseno(X_train) + X_train * 0.1\n",
    "\n",
    "# Se arman los valores para X_test e y_test\n",
    "# X_test almacena una array con 100 valores en el rango de a a 1 \n",
    "X_test = np.linspace(0, 1, 100)\n",
    "\n",
    "# Los valores y_test serán 100 valores producto de aplicar la función coseno\n",
    "y_test = coseno(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFz_NJilB8zF"
   },
   "source": [
    "### La regresión polinomial busca la curva que mejor se ajusta a los datos. \n",
    "\n",
    "Una vez conseguido, los datos se ajustan y se puede aplicar una regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tdixhcUJ17-G"
   },
   "outputs": [],
   "source": [
    "# Se importa el algoritmo de sklearn.preprocessing  como PolynomialFeatures\n",
    "# Se importa la métrica de sklearn.metrics como mean_squared_error(MSE)\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Se tendrán dos variables con listas vacías que almacenarán\n",
    "# Una mse_list, los errores\n",
    "# grados_list, almacenará los grados del polinomio de cada entrenamiento \n",
    "mse_list = []\n",
    "grados_list = []\n",
    "\n",
    "# El bucle iterará 9 veces, para degree 1,2,3,4,5,6,7,8,9\n",
    "for degree in range(1, 10):\n",
    "\n",
    "    # Se crea el objeto polynomial_features a partir de la clase  PolynomialFeatures()\n",
    "    # y se indica la variable degree    \n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    \n",
    "    # Se aplica el método fit_transform indicando los X para entrenar y evaluar\n",
    "    # haciendo un ajuste con reshape\n",
    "    X_train_poly = poly.fit_transform(X_train.reshape(-1, 1))\n",
    "    X_test_poly = poly.fit_transform(X_test.reshape(-1, 1))\n",
    "\n",
    "    # Se aplica una regresión lineal una vez conseguido los valores para X_train y X_test del polinomio \n",
    "    # Se crea el objeto de regresión lineal\n",
    "    # Se aplica el método fin con los X del polinomio\n",
    "    # Luego se hace el predict\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train_poly, y_train)\n",
    "    y_hat = lr.predict(X_test_poly)\n",
    "\n",
    "    # Se calcula el error (MSE)\n",
    "    mse = mean_squared_error(y_test, y_hat)\n",
    "\n",
    "    # El error en cada iteración se va guardando en la lista mse_list\n",
    "    mse_list.append(mse)\n",
    "\n",
    "    # Al igual que el grado del polinomio\n",
    "    grados_list.append(degree)\n",
    "\n",
    "    # Asi como también, en cada iteración se hace un print del grado y error.\n",
    "    print(f\"Gradio de polinomio {degree}, error: {mse}\") # print del error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37MuzY983NJc"
   },
   "outputs": [],
   "source": [
    "# Representación gráfica de linea\n",
    "# De los grados con respecto al error\n",
    "plt.title(\"Nivel óptimo de complejidad del modelo\")\n",
    "plt.plot(grados_list, mse_list, label=\"test\")\n",
    "\n",
    "# Identificación del eje y \n",
    "plt.ylabel(\"Error\")\n",
    "plt.show()\n",
    "\n",
    "# Print de error más bajo y el grado que corresponde a ese error\n",
    "print('Error mínimo:', min(mse_list))\n",
    "print('Nivel óptimo:', mse_list.index(min(mse_list))+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9VP0EIxwCI0B"
   },
   "outputs": [],
   "source": [
    "# Se importa el algoritmo de  sklearn.preprocessing  como PolynomialFeatures\n",
    "# Se importa el normalizador como MinMaxScaler de sklearn.preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Se crea el objeto poly\n",
    "poly = PolynomialFeatures(degree=8)\n",
    "\n",
    "# Se aplica fit_transform con el grado con menor error\n",
    "X_train_poly = poly.fit_transform(X_train.reshape(-1, 1))\n",
    "X_test_poly = poly.fit_transform(X_test.reshape(-1, 1))\n",
    "\n",
    "# Una vez que se tienen los valores de X del polinomio identificado \n",
    "# Se aplica una regresiín lineal con los nuevos valore de X\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_poly, y_train)\n",
    "y_hat = lr.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p04gC6QL2Cn3"
   },
   "source": [
    "## 6 - Regresión con gradiente descendente\n",
    "Nota: Se hablará y explicará más sobre el gradiente descendente en la clase en redes neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ecPSPpYT2GZD"
   },
   "outputs": [],
   "source": [
    "# Se importa el algoritmo de sklearn.linear_model  como SGDRegressor\n",
    "# Se importa el normalizador como MinMaxScaler de sklearn.preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Se crea el objeto scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Se aplica el método fit para los valores de X ajustados con un reshape(1,-1)\n",
    "scaler.fit(X.reshape(-1, 1))\n",
    "\n",
    "# Se aplica el método transform para los valores de X ajustados con un reshape(1,-1)\n",
    "X_norm = scaler.transform(X.reshape(-1, 1))\n",
    "\n",
    "# Se crea el objeto a partir de la clase SGDRegressor indicando el max_iter(Máximo de iteraciones)\n",
    "#  tol=0.01, criterio para detenerse y obterner el siguiente valor\n",
    "reg = SGDRegressor(max_iter=1000, tol=0.01)\n",
    "\n",
    "# Se entrena con fit y los valores X_norm, y\n",
    "reg.fit(X_norm, y)\n",
    "\n",
    "# Y se aplica el predict para obtener las predicciones de X_norm\n",
    "y_hat = reg.predict(X_norm)\n",
    "\n",
    "# Se muestra la pendiente \n",
    "# Y el punto donde la recta pasa por el eje y\n",
    "\n",
    "print(f\"Pendiente (W1): {reg.coef_[0]:.2f}\")\n",
    "print(f\"Ordenada al origen (W0):\", reg.intercept_)\n",
    "print(\"Ojo! Los coeficientes fueron afectados por la normalización, no es conveniente utilizarlos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMtThoBo33BV"
   },
   "outputs": [],
   "source": [
    "# Se representa graficamente la recta del gradiente, los puntos correctamente estimados y los datos\n",
    "\n",
    "# Para ello se crea un array de valores para aplicar la normalización y posteriomente el predict\n",
    "lx3 = np.array([0, X.max()])\n",
    "lx3_norm = scaler.transform(lx3.reshape(-1, 1))\n",
    "ly3 = reg.predict(lx3_norm)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "sns.scatterplot(x=X, y=y, label='datos', ax=ax, color='darkcyan')\n",
    "sns.scatterplot(x=X, y=y_hat, color='r', ax=ax, label='puntos predicción')\n",
    "sns.lineplot(x=lx3, y=ly3, label='recta gradiente', color='b', ax=ax)\n",
    "ax.legend()\n",
    "ax.grid('dashed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pu81kTK268zw"
   },
   "outputs": [],
   "source": [
    "# Es un coeficiente de determinación, determina la capacidad de un modelo para predecir futuros resultados. \n",
    "# El mejor resultado posible es 1.0\n",
    "from sklearn.metrics import r2_score\n",
    "reg_r2 = r2_score(y, y_hat)\n",
    "print(f\"Gradiente: coeficiente de deterinación: {reg_r2:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
